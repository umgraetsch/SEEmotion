{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook should be run SE Emotion Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pickle\n",
    "filename = 'C:\\\\Users\\\\umg\\\\Development\\\\SEmotion\\\\03_Journal\\\\Data\\\\merged_training.pkl'\n",
    "infile = open(filename,'rb')\n",
    "training_data = pickle.load(infile)\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27383</th>\n",
       "      <td>i feel awful about it too because it s my job ...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110083</th>\n",
       "      <td>im alone i feel awful</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140764</th>\n",
       "      <td>ive probably mentioned this before but i reall...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100071</th>\n",
       "      <td>i was feeling a little low few days back</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2837</th>\n",
       "      <td>i beleive that i am much more sensitive to oth...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text emotions\n",
       "27383   i feel awful about it too because it s my job ...  sadness\n",
       "110083                              im alone i feel awful  sadness\n",
       "140764  ive probably mentioned this before but i reall...      joy\n",
       "100071           i was feeling a little low few days back  sadness\n",
       "2837    i beleive that i am much more sensitive to oth...     love"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text        416809\n",
       "emotions    416809\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x19e12d46108>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_data.emotions.value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data.to_csv('C:\\\\Users\\\\umg\\\\Development\\\\SEmotion\\\\03_Journal\\\\Data\\\\training_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\umg\\.conda\\envs\\SE Emotion\\lib\\site-packages\\transformers\\modeling_auto.py:798: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelWithLMHead\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mrm8488/t5-small-finetuned-emotion\")\n",
    "\n",
    "model = AutoModelWithLMHead.from_pretrained(\"mrm8488/t5-small-finetuned-emotion\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emotion(text):\n",
    "  input_ids = tokenizer.encode(text + '</s>', return_tensors='pt')\n",
    "\n",
    "  output = model.generate(input_ids=input_ids,\n",
    "               max_length=2)\n",
    "\n",
    "  dec = [tokenizer.decode(ids) for ids in output]\n",
    "  label = dec[0]\n",
    "  return label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nicely formated timespan from Jeff Heaton\n",
    "def hms_string(sec_elapsed):\n",
    "    h = int(sec_elapsed / (60*60))\n",
    "    m = int((sec_elapsed % (60*60)) / 60)\n",
    "    s = sec_elapsed % 60\n",
    "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'joy'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " get_emotion(\"i feel as if i havent blogged in ages are at least truly blogged i am doing an update cute\") # Output: 'joy'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sadness'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " get_emotion(\"i have a feeling i kinda lost my best friend\") # Output: 'sadness'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'joy'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_emotion(\"I want to build a cloud \"\"based\"\" solution in which I would give a pool of images; and then ask for find similar image to a particular image from this pool of images !! Pool of images can be like all t-shirt images. Hence, similar images mean t-shirt with similar design/color/sleeves etc.Tagging solution won't work as they are at very high level.AWS Rekognition gives facial similarities .. but not product similarities .. it does not work like for images of dresses..I am open to use any cloud providers; but all are providing tags of the image which won't help me.One solution could be that I use some ML framework like MXNet/Tensorflow, create my own models, train them and then use.. But is there any other ready made solution on any of cloud providers ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fear'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_emotion(\"Using Airflow I want to get the result of an SQL Query fomratted as a pandas DataFrame.Above is the python function that I want to execute in a. Here is the DAG:But, the work step is throwing an exception. Here is the log :This exception is due to this, which accroding to the descriptionhides another exception, still strange because I'm not doing any insertion.What am I doing wrong? Maybe there is a problem withused in the. Or, dataFrame is not the way to go in order to handle query results.PS: result of\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'anger'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_emotion(\"I am trying to use aws rekognition to compare faces but it will give an error saying check if the object and bucket exist in same regionwhile uploading the image i have set the content type to image/jpeg formatbut when i upload an image using aws console from computer the rekognition will work ! am i doing something wrong in this code\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in the visionAPIClassificationFile - the important columns are \"ID\" and \"Question Text\"\n",
    "import pandas as pd\n",
    "visionapi_df = pd.DataFrame\n",
    "filename = 'C:\\\\Users\\\\umg\\\\Development\\\\SEmotion\\\\03_Journal\\\\Data\\VisionAPIQuestions_source.csv'\n",
    "visionapi_df = pd.read_csv(filename, sep=',', )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nicely formated timespan from Jeff Heaton\n",
    "def hms_string(sec_elapsed):\n",
    "    h = int(sec_elapsed / (60*60))\n",
    "    m = int((sec_elapsed % (60*60)) / 60)\n",
    "    s = sec_elapsed % 60\n",
    "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Strip out the delimit the \"\" so that HuggingFace API calls will work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have processed questions 100\n",
      "We have processed questions 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (650 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have processed questions 300\n",
      "We have processed questions 400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (537 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have processed questions 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (791 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have processed questions 600\n",
      "We have processed questions 700\n",
      "We have processed questions 800\n",
      "We have processed questions 900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (588 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have processed questions 1,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1215 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have processed questions 1,100\n",
      "We have processed questions 1,200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (569 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total pre-processing runtime: 0:01:40.05\n"
     ]
    }
   ],
   "source": [
    "#Process the Vision API dataframe and write result to CSV file\n",
    "import time\n",
    "totalCount = 0\n",
    "start_time = time.time()\n",
    "result_df = visionapi_df.copy()  # take a copy of the dataframe\n",
    "\n",
    "for index, row in result_df.iterrows():\n",
    "    totalCount+=1\n",
    "    result_df.loc[index,'T5Result'] = get_emotion(row['Question Text']) \n",
    "    if totalCount > 1 and (totalCount % 100) == 0:\n",
    "        print(\"We have processed questions {:,}\".format(totalCount))\n",
    "time_took = time.time() - start_time\n",
    "print(f\"Total pre-processing runtime: {hms_string(time_took)}\")\n",
    "t5filename = 'C:\\\\Users\\\\umg\\\\Development\\\\SEmotion\\\\03_Journal\\\\Data\\VisionAPIQuestions_T5out.csv'\n",
    "result_df.to_csv(t5filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv(t5filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>FearID</th>\n",
       "      <th>fear</th>\n",
       "      <th>JoyID</th>\n",
       "      <th>joy</th>\n",
       "      <th>LoveID</th>\n",
       "      <th>love</th>\n",
       "      <th>SadID</th>\n",
       "      <th>Sadness</th>\n",
       "      <th>SurpriseID</th>\n",
       "      <th>surprise</th>\n",
       "      <th>AngerID</th>\n",
       "      <th>anger</th>\n",
       "      <th>NoEmotionID</th>\n",
       "      <th>none</th>\n",
       "      <th>NoOfEmotions</th>\n",
       "      <th>Include</th>\n",
       "      <th>Question Text</th>\n",
       "      <th>T5Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45033467</td>\n",
       "      <td>45033467</td>\n",
       "      <td>fear</td>\n",
       "      <td>45033467</td>\n",
       "      <td>NoJoy</td>\n",
       "      <td>45033467</td>\n",
       "      <td>love</td>\n",
       "      <td>45033467</td>\n",
       "      <td>notsadness</td>\n",
       "      <td>45033467</td>\n",
       "      <td>notsurprise</td>\n",
       "      <td>45033467</td>\n",
       "      <td>NotAnger</td>\n",
       "      <td>45033467</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>\"I want to build a cloud based solution in whi...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45546462</td>\n",
       "      <td>45546462</td>\n",
       "      <td>fear</td>\n",
       "      <td>45546462</td>\n",
       "      <td>NoJoy</td>\n",
       "      <td>45546462</td>\n",
       "      <td>notlove</td>\n",
       "      <td>45546462</td>\n",
       "      <td>notsadness</td>\n",
       "      <td>45546462</td>\n",
       "      <td>notsurprise</td>\n",
       "      <td>45546462</td>\n",
       "      <td>NotAnger</td>\n",
       "      <td>45546462</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>YES</td>\n",
       "      <td>\"I have problem with access to camera first ti...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49619897</td>\n",
       "      <td>49619897</td>\n",
       "      <td>notfear</td>\n",
       "      <td>49619897</td>\n",
       "      <td>NoJoy</td>\n",
       "      <td>49619897</td>\n",
       "      <td>notlove</td>\n",
       "      <td>49619897</td>\n",
       "      <td>notsadness</td>\n",
       "      <td>49619897</td>\n",
       "      <td>surprise</td>\n",
       "      <td>49619897</td>\n",
       "      <td>Anger</td>\n",
       "      <td>49619897</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>\"Using Airflow I want to get the result of an ...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55388663</td>\n",
       "      <td>55388663</td>\n",
       "      <td>notfear</td>\n",
       "      <td>55388663</td>\n",
       "      <td>NoJoy</td>\n",
       "      <td>55388663</td>\n",
       "      <td>notlove</td>\n",
       "      <td>55388663</td>\n",
       "      <td>notsadness</td>\n",
       "      <td>55388663</td>\n",
       "      <td>notsurprise</td>\n",
       "      <td>55388663</td>\n",
       "      <td>NotAnger</td>\n",
       "      <td>55388663</td>\n",
       "      <td>NoEmotion</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>\"I try to use Google Cloud Vision API to detec...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52833231</td>\n",
       "      <td>52833231</td>\n",
       "      <td>notfear</td>\n",
       "      <td>52833231</td>\n",
       "      <td>NoJoy</td>\n",
       "      <td>52833231</td>\n",
       "      <td>notlove</td>\n",
       "      <td>52833231</td>\n",
       "      <td>notsadness</td>\n",
       "      <td>52833231</td>\n",
       "      <td>notsurprise</td>\n",
       "      <td>52833231</td>\n",
       "      <td>NotAnger</td>\n",
       "      <td>52833231</td>\n",
       "      <td>NoEmotion</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>\"How can i write a test case in Junit for amaz...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID    FearID     fear     JoyID    joy    LoveID     love     SadID  \\\n",
       "0  45033467  45033467     fear  45033467  NoJoy  45033467     love  45033467   \n",
       "1  45546462  45546462     fear  45546462  NoJoy  45546462  notlove  45546462   \n",
       "2  49619897  49619897  notfear  49619897  NoJoy  49619897  notlove  49619897   \n",
       "3  55388663  55388663  notfear  55388663  NoJoy  55388663  notlove  55388663   \n",
       "4  52833231  52833231  notfear  52833231  NoJoy  52833231  notlove  52833231   \n",
       "\n",
       "      Sadness  SurpriseID     surprise   AngerID     anger  NoEmotionID  \\\n",
       "0  notsadness    45033467  notsurprise  45033467  NotAnger     45033467   \n",
       "1  notsadness    45546462  notsurprise  45546462  NotAnger     45546462   \n",
       "2  notsadness    49619897     surprise  49619897     Anger     49619897   \n",
       "3  notsadness    55388663  notsurprise  55388663  NotAnger     55388663   \n",
       "4  notsadness    52833231  notsurprise  52833231  NotAnger     52833231   \n",
       "\n",
       "        none  NoOfEmotions Include  \\\n",
       "0        NaN           2.0     Yes   \n",
       "1        NaN           1.0     YES   \n",
       "2        NaN           2.0     Yes   \n",
       "3  NoEmotion           0.0     Yes   \n",
       "4  NoEmotion           0.0     Yes   \n",
       "\n",
       "                                       Question Text T5Result  \n",
       "0  \"I want to build a cloud based solution in whi...      joy  \n",
       "1  \"I have problem with access to camera first ti...      joy  \n",
       "2  \"Using Airflow I want to get the result of an ...     fear  \n",
       "3  \"I try to use Google Cloud Vision API to detec...      joy  \n",
       "4  \"How can i write a test case in Junit for amaz...      joy  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
